---
---
@inproceedings{
spanishmi,
title={Examining Spanish Counseling with {MIDAS}: a Motivational Interviewing Dataset in Spanish},
author={Aylin Ece Gunal and Bowen Yi and John D. Piette and Rada Mihalcea and Veronica Perez-Rosas},
booktitle={NAACL},
year={2025},
url={https://openreview.net/forum?id=tReVq0bFUX},
abstract={Cultural and language factors significantly impact counseling, yet NLP studies have not explored the applicability of English counseling findings to other languages, which is crucial for multicultural countries like the US. Seeking to contribute to this line of work, this paper introduces MIDAS, a new Motivational Interviewing Dataset in Spanish created from public video sources and expert annotations. It includes annotations for counseling reflections and questions. We use it to explore language-based differences in counselor behavior in English and Spanish MI, and develop classifiers in monolingual and multilingual contexts to demonstrate the dataset's value for behavioral coding tasks.},
pdf={https://openreview.net/pdf?id=cSHpYEx8zP}
}

@inproceedings{Research-jam-2024,
  title={Causally Modeling the Linguistic and Social Factors that Predict Email ResponseCausally Modeling the Linguistic and Social Factors that Predict Email Response},
  author={Yinuo Xu* and ... and Bowen Yi* and ... and David Jurgens},
  booktitle={NAACL},
  year={2025},
url={https://openreview.net/forum?id=2JwDE5xWxk},
  abstract={Email is a vital conduit for human communication across businesses, organizations, and broader societal contexts. In this study, we aim to model the intents, expectations, and responsiveness in email exchanges. To this end, we create SIZZLER, a new dataset containing 1800 emails annotated with nuanced types of intents and expectations. We benchmark models ranging from feature-based logistic regression to zero-shot prompting of large language models. Leveraging the predictive model for intent, expectations, and 14 other categories of pragmatic features, we analyze 11.3M emails from GMANE to study the conversational dynamics in email exchanges. Through our causal analysis, we find that the email response rates are influenced by social status, argumentation, and in certain limited contexts, the strength of social connection. Our code and data are available upon acceptance.},
  pdf={https://openreview.net/pdf?id=GFButsuEo0}
}

@misc{yi2025unveilingbehavioraldifferencesbilingual,
      title={Unveiling Behavioral Differences in Bilingual Information Operations: A Network-Based Approach}, 
      author={Bowen Yi},
      note={In Submission to IC2S2, Preprint on arXiv},
      year={2025},
      eprint={2501.09027},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/2501.09027}, 
      abstract={Twitter has become a pivotal platform for conducting information operations (IOs), particularly during high-stakes political events. In this study, we analyze over a million tweets about the 2024 U.S. presidential election to explore an under-studied area: the behavioral differences of IO drivers from English- and Spanish-speaking communities. Using similarity graphs constructed from behavioral patterns, we identify IO drivers in both languages and evaluate the clustering quality of these graphs in an unsupervised setting. Our analysis demonstrates how different network dismantling strategies, such as node pruning and edge filtering, can impact clustering quality and the identification of coordinated IO drivers. We also reveal significant differences in the topics and political indicators between English and Spanish IO drivers. Additionally, we investigate bilingual users who post in both languages, systematically uncovering their distinct roles and behaviors compared to monolingual users. These findings underscore the importance of robust, culturally and linguistically adaptable IO detection methods to mitigate the risks of influence campaigns on social media. Our code and data are available on GitHub: this https URL. }
}

@inproceedings{liu-etal-2024-generation-gap,
    title = "The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models",
    author = "Liu, Siyang  and
      Maturi, Trisha  and
      Yi, Bowen  and
      Shen, Siqi  and
      Mihalcea, Rada",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.1094/",
    doi = "10.18653/v1/2024.emnlp-main.1094",
    pages = "19617--19634",
    abstract = "We explore the alignment of values in Large Language Models (LLMs) with specific age groups, leveraging data from the World Value Survey across thirteen categories. Through a diverse set of prompts tailored to ensure response robustness, we find a general inclination of LLM values towards younger demographics, especially when compared to the US population. Although a general inclination can be observed, we also found that this inclination toward younger groups can be different across different value categories. Additionally, we explore the impact of incorporating age identity information in prompts and observe challenges in mitigating value discrepancies with different age cohorts. Our findings highlight the age bias in LLMs and provide insights for future work. Materials for our analysis will be available via \url{https://github.com/anonymous}"
}



@unpublished{medicalintern,
  title={Uncovering the Impact of Intervention Messages on Diverse Population Groups},
  author={Bowen Yi and Rada Mihalcea and Fang Yu and Elena Frank and Joan Zhao and Srijan Sen and Maggie Makar},
  note={Working Paper},
  year={2024}, 
  abstract={Medical interns usually face mental health challenges due to the demanding nature of their working environments. In this context, intervention messages are delivered to their mobile devices to support them in maintaining healthy behavior. This study investigates the effectiveness of various intervention messages by analyzing their conditional average causal effects on health outcomes such as steps, mood, and sleep. We identify linguistic features, including LIWC, and factors encoded by medical experts, such as cognitive strategies, that contribute to the efficacy of these interventions. To handle the high dimensionality of our treatment variables, we develop methods that balance the tradeoff between overlapping and positivity assumptions of causal inference. In addition, we introduce a decision tree-based approach to identify subgroups that respond differently to interventions. It shows higher stability than previous approaches against small data variations. Our research, validated on a 4-year dataset involving over 6,000 medical interns from 250 U.S. medical programs, offers valuable insights for designing more effective, subgroup-aware intervention strategies in healthcare.},
}

@misc{Research-jam-summer-2024,
  title={Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue},
  author={Johnathan Ivey* and ... and Bowen Yi* and ... and David Jurgens},
  note={In Submission to ACL 2025. * denotes equal contribution with randomized order.},
  year={2024}, 
  eprint={2404.08760},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url = "https://arxiv.org/abs/2409.08330v1",
  pdf = "https://arxiv.org/pdf/2409.08330v1",
  abstract={Studying and building datasets for dialogue tasks is both expensive and time-consuming due to the need to recruit, train, and collect data from study participants. In response, much recent work has sought to use large language models (LLMs) to simulate both human-human and human-LLM interactions, as they have been shown to generate convincingly human-like text in many settings. However, to what extent do LLM-based simulations \textit{actually} reflect human dialogues? In this work, we answer this question by generating a large-scale dataset of 100,000 paired LLM-LLM and human-LLM dialogues from the WildChat dataset and quantifying how well the LLM simulations align with their human counterparts. Overall, we find relatively low alignment between simulations and human interactions, demonstrating a systematic divergence along the multiple textual properties, including style and content. Further, in comparisons of English, Chinese, and Russian dialogues, we find that models perform similarly. Our results suggest that LLMs generally perform better when the human themself writes in a way that is more similar to the LLM's own style.},
}


